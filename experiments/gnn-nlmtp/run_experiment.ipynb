{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77c89ac9",
   "metadata": {},
   "source": [
    "# NL-MTP HoF Experiment\n",
    "\n",
    "Homoiconic transformer with fast-weights (LoR) for MTP policy evaluation on HoF.\n",
    "\n",
    "## Setup\n",
    "\n",
    "- **Objective**: Train a transformer to perform policy evaluation (MTP) under δ=+14 Da shift\n",
    "- **Architecture**: 12-layer transformer with LoR at layers {3,7,11}, rank=8\n",
    "- **Losses**: DR/AIPW + MDN propensity + REx invariance + LoR locality\n",
    "- **Data**: BOOM HoF splits with RDKit features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59672243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Imports and setup\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from pathlib import Path\n",
    "\n",
    "# Add repo root to path\n",
    "repo_root = Path.cwd().parent.parent\n",
    "sys.path.insert(0, str(repo_root))\n",
    "\n",
    "# Import experiment modules\n",
    "try:\n",
    "    from dataset import make_dataloaders\n",
    "    from model import NL_MTP_Model\n",
    "    from trainer import train_epoch, evaluate\n",
    "    from eval import save_metrics_json, make_all_plots\n",
    "except ImportError:\n",
    "    sys.path.insert(0, str(Path.cwd()))\n",
    "    from dataset import make_dataloaders\n",
    "    from model import NL_MTP_Model\n",
    "    from trainer import train_epoch, evaluate\n",
    "    from eval import save_metrics_json, make_all_plots\n",
    "\n",
    "# Device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f812a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration:\n",
      "  batch_size: 64\n",
      "  epochs: 30\n",
      "  delta: 14.0\n",
      "  lr: 0.0002\n",
      "  warmup_epochs: 5\n",
      "  out_dir: results\n",
      "  emb_dim: 512\n",
      "  num_layers: 12\n",
      "  num_heads: 8\n",
      "  dim_ff: 2048\n",
      "  lor_layers: (3, 7, 11)\n",
      "  lor_rank: 8\n",
      "  mdn_components: 8\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "config = {\n",
    "    'batch_size': 64,\n",
    "    'epochs': 30,\n",
    "    'delta': 14.0,\n",
    "    'lr': 2e-4,\n",
    "    'warmup_epochs': 5,\n",
    "    'out_dir': 'results',\n",
    "    \n",
    "    # Model\n",
    "    'emb_dim': 512,\n",
    "    'num_layers': 12,\n",
    "    'num_heads': 8,\n",
    "    'dim_ff': 2048,\n",
    "    'lor_layers': (3, 7, 11),\n",
    "    'lor_rank': 8,\n",
    "    'mdn_components': 8,\n",
    "}\n",
    "\n",
    "os.makedirs(config['out_dir'], exist_ok=True)\n",
    "print(\"Configuration:\")\n",
    "for k, v in config.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92047c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "File downloaded successfully and saved as c:\\Users\\prapa\\Documents\\GitHub\\BOOM-TTE\\experiments\\gnn-nlmtp\\10k_dft_density_data.csv\n",
      "File downloaded successfully and saved as c:\\Users\\prapa\\Documents\\GitHub\\BOOM-TTE\\experiments\\gnn-nlmtp\\10k_dft_hof_data.csv\n",
      "There are 1000 OOD density samples. There are 1000 OOD hof samples. There are 440 IID density samples. There are 423 IID hof samples.\n",
      "Train batches: 138\n",
      "ID batches: 7\n",
      "OOD batches: 16\n",
      "\n",
      "Sample batch shapes:\n",
      "  x_ctx: torch.Size([64, 2223])\n",
      "  mw: torch.Size([64])\n",
      "  y: torch.Size([64])\n",
      "  env_idx: torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "print(\"Loading data...\")\n",
    "loaders = make_dataloaders(batch_size=config['batch_size'])\n",
    "train_dl, id_dl, ood_dl = loaders\n",
    "\n",
    "print(f\"Train batches: {len(train_dl)}\")\n",
    "print(f\"ID batches: {len(id_dl)}\")\n",
    "print(f\"OOD batches: {len(ood_dl)}\")\n",
    "\n",
    "# Check a sample\n",
    "sample = next(iter(train_dl))\n",
    "print(f\"\\nSample batch shapes:\")\n",
    "for k, v in sample.items():\n",
    "    print(f\"  {k}: {v.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03e057e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing model...\n",
      "Total params: 40,939,044\n",
      "Trainable params: 40,939,044\n"
     ]
    }
   ],
   "source": [
    "# Initialize model\n",
    "print(\"Initializing model...\")\n",
    "model = NL_MTP_Model(\n",
    "    emb_dim=config['emb_dim'],\n",
    "    num_layers=config['num_layers'],\n",
    "    num_heads=config['num_heads'],\n",
    "    dim_ff=config['dim_ff'],\n",
    "    lor_layers=config['lor_layers'],\n",
    "    lor_rank=config['lor_rank'],\n",
    "    mdn_components=config['mdn_components'],\n",
    ").to(device)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total params: {total_params:,}\")\n",
    "print(f\"Trainable params: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb6c50f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 4140\n",
      "Warmup steps: 414\n"
     ]
    }
   ],
   "source": [
    "# Optimizer and scheduler\n",
    "opt = optim.AdamW(model.parameters(), lr=config['lr'], weight_decay=1e-2)\n",
    "\n",
    "total_steps = config['epochs'] * len(train_dl)\n",
    "warmup_steps = min(2000, total_steps // 10)\n",
    "\n",
    "sched = optim.lr_scheduler.OneCycleLR(\n",
    "    opt,\n",
    "    max_lr=config['lr'],\n",
    "    total_steps=total_steps,\n",
    "    pct_start=warmup_steps / total_steps,\n",
    "    anneal_strategy='cos',\n",
    ")\n",
    "\n",
    "print(f\"Total steps: {total_steps}\")\n",
    "print(f\"Warmup steps: {warmup_steps}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8163696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training for 30 epochs...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "print(f\"\\nTraining for {config['epochs']} epochs...\\n\")\n",
    "\n",
    "best_ood_rmse = float('inf')\n",
    "history = []\n",
    "\n",
    "for epoch in range(1, config['epochs'] + 1):\n",
    "    # Train\n",
    "    train_metrics = train_epoch(\n",
    "        model,\n",
    "        loaders,\n",
    "        opt,\n",
    "        sched,\n",
    "        delta=config['delta'],\n",
    "        epoch=epoch,\n",
    "        device=device,\n",
    "        warmup_epochs=config['warmup_epochs'],\n",
    "    )\n",
    "    \n",
    "    # Evaluate\n",
    "    val_metrics = evaluate(model, loaders, delta=config['delta'], device=device)\n",
    "    \n",
    "    # Log\n",
    "    print(f\"Epoch {epoch}/{config['epochs']}\")\n",
    "    print(f\"  Train Loss: {train_metrics['train_loss']:.4f} \"\n",
    "          f\"(obs={train_metrics['L_obs']:.4f}, mdn={train_metrics['L_mdn']:.4f}, \"\n",
    "          f\"dr_func={train_metrics['L_dr_func']:.4f}, rex={train_metrics['L_rex']:.4f})\")\n",
    "    print(f\"  ID:  RMSE={val_metrics['id_rmse']:.4f}, MAE={val_metrics['id_mae']:.4f}, \"\n",
    "          f\"Contrast={val_metrics['id_policy_contrast']:.4f}\")\n",
    "    print(f\"  OOD: RMSE={val_metrics['ood_rmse']:.4f}, MAE={val_metrics['ood_mae']:.4f}, \"\n",
    "          f\"Contrast={val_metrics['ood_policy_contrast']:.4f}\")\n",
    "    \n",
    "    # Save best\n",
    "    if val_metrics['ood_rmse'] < best_ood_rmse:\n",
    "        best_ood_rmse = val_metrics['ood_rmse']\n",
    "        torch.save(model.state_dict(), os.path.join(config['out_dir'], 'best_model.pth'))\n",
    "        print(f\"  *** New best OOD RMSE: {best_ood_rmse:.4f} ***\")\n",
    "    \n",
    "    # Store history\n",
    "    history.append({\n",
    "        'epoch': epoch,\n",
    "        **train_metrics,\n",
    "        **{k: v for k, v in val_metrics.items() if not isinstance(v, torch.Tensor)}\n",
    "    })\n",
    "\n",
    "print(\"\\nTraining complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74aefb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final evaluation\n",
    "print(\"=\"*60)\n",
    "print(\"Final Evaluation\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "model.load_state_dict(torch.load(os.path.join(config['out_dir'], 'best_model.pth')))\n",
    "final_metrics = evaluate(model, loaders, delta=config['delta'], device=device)\n",
    "\n",
    "print(f\"\\nID:  RMSE={final_metrics['id_rmse']:.4f}, MAE={final_metrics['id_mae']:.4f}\")\n",
    "print(f\"OOD: RMSE={final_metrics['ood_rmse']:.4f}, MAE={final_metrics['ood_mae']:.4f}\")\n",
    "print(f\"\\nPolicy contrast (Δpred):\")\n",
    "print(f\"  ID:  {final_metrics['id_policy_contrast']:.4f}\")\n",
    "print(f\"  OOD: {final_metrics['ood_policy_contrast']:.4f}\")\n",
    "print(f\"\\nAlpha (LoR gate):\")\n",
    "print(f\"  ID:  {final_metrics['id_alpha']:.4f}\")\n",
    "print(f\"  OOD: {final_metrics['ood_alpha']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2265c75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "save_metrics_json(final_metrics, os.path.join(config['out_dir'], 'metrics.json'))\n",
    "make_all_plots(final_metrics, config['out_dir'])\n",
    "\n",
    "print(f\"\\nResults saved to {config['out_dir']}\")\n",
    "print(f\"  - metrics.json\")\n",
    "print(f\"  - NL_MTP_HoF_ID_parity.png\")\n",
    "print(f\"  - NL_MTP_HoF_OOD_parity.png\")\n",
    "print(f\"  - best_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a115b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(history)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "\n",
    "# Loss\n",
    "axes[0, 0].plot(df['epoch'], df['train_loss'], label='Train Loss')\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Loss')\n",
    "axes[0, 0].set_title('Training Loss')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(alpha=0.3)\n",
    "\n",
    "# RMSE\n",
    "axes[0, 1].plot(df['epoch'], df['id_rmse'], label='ID')\n",
    "axes[0, 1].plot(df['epoch'], df['ood_rmse'], label='OOD')\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('RMSE')\n",
    "axes[0, 1].set_title('RMSE over Epochs')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(alpha=0.3)\n",
    "\n",
    "# Loss components\n",
    "axes[1, 0].plot(df['epoch'], df['L_obs'], label='L_obs')\n",
    "axes[1, 0].plot(df['epoch'], df['L_mdn'], label='L_mdn')\n",
    "axes[1, 0].plot(df['epoch'], df['L_dr_func'], label='L_DR-func')\n",
    "axes[1, 0].plot(df['epoch'], df['L_rex'], label='L_rex')\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('Loss')\n",
    "axes[1, 0].set_title('Loss Components')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(alpha=0.3)\n",
    "\n",
    "# Policy contrast\n",
    "axes[1, 1].plot(df['epoch'], df['id_policy_contrast'], label='ID')\n",
    "axes[1, 1].plot(df['epoch'], df['ood_policy_contrast'], label='OOD')\n",
    "axes[1, 1].set_xlabel('Epoch')\n",
    "axes[1, 1].set_ylabel('Δpred (Policy Contrast)')\n",
    "axes[1, 1].set_title('Policy Contrast over Epochs')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(config['out_dir'], 'training_history.png'), dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(\"Training history plot saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9023b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display parity plots\n",
    "from IPython.display import Image, display\n",
    "\n",
    "print(\"ID Parity Plot:\")\n",
    "display(Image(filename=os.path.join(config['out_dir'], 'NL_MTP_HoF_ID_parity.png')))\n",
    "\n",
    "print(\"\\nOOD Parity Plot:\")\n",
    "display(Image(filename=os.path.join(config['out_dir'], 'NL_MTP_HoF_OOD_parity.png')))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
