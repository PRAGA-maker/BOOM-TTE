# BOOM-TTE Progress Tracking

## Datasets Status

| Dataset | Property | Status | Train Size | ID Size | OOD Size | Notes |
|---------|----------|--------|------------|---------|----------|-------|
| 10K CSD | Density | ‚úÖ Loaded | 8766 | 440 | 1000 | Auto-downloaded from LLNL GitHub |
| 10K CSD | HoF | ‚úÖ Loaded | 8783 | 423 | 1000 | Auto-downloaded from LLNL GitHub |
| QM9 | Alpha | ‚úÖ Loaded | 117768 | ~5000 | 10000 | Downloaded from Figshare, processed |
| QM9 | Cv | ‚úÖ Loaded | 117768 | ~5000 | 10000 | Downloaded from Figshare, processed |
| QM9 | Gap | ‚úÖ Loaded | 117768 | ~5000 | 10000 | Downloaded from Figshare, processed |
| QM9 | HOMO | ‚úÖ Loaded | 117768 | ~5000 | 10000 | Downloaded from Figshare, processed |
| QM9 | LUMO | ‚úÖ Loaded | 117768 | ~5000 | 10000 | Downloaded from Figshare, processed |
| QM9 | Mu | ‚úÖ Loaded | 117768 | ~5000 | 10000 | Downloaded from Figshare, processed |
| QM9 | R2 | ‚úÖ Loaded | 117768 | ~5000 | 10000 | Downloaded from Figshare, processed |
| QM9 | ZPVE | ‚úÖ Loaded | 117768 | ~5000 | 10000 | Downloaded from Figshare, processed |

## Models Status

### Baseline Models
| Model | Density | HoF | Alpha | Cv | Gap | HOMO | LUMO | Mu | R2 | ZPVE | Status |
|-------|---------|-----|-------|----|----|------|------|----|----|------|--------|
| Random Forest | ‚è≥ | ‚è≥ | ‚è≥ | ‚è≥ | ‚è≥ | ‚è≥ | ‚è≥ | ‚è≥ | ‚è≥ | ‚è≥ | Ready to run |

### Advanced Models
| Model | Density | HoF | Alpha | Cv | Gap | HOMO | LUMO | Mu | R2 | ZPVE | Status |
|-------|---------|-----|-------|----|----|------|------|----|----|------|--------|
| Chemprop | ‚è≥ | ‚è≥ | ‚è≥ | ‚è≥ | ‚è≥ | ‚è≥ | ‚è≥ | ‚è≥ | ‚è≥ | ‚è≥ | Needs setup |
| Graphormer3D | ‚è≥ | ‚è≥ | ‚è≥ | ‚è≥ | ‚è≥ | ‚è≥ | ‚è≥ | ‚è≥ | ‚è≥ | ‚è≥ | Needs setup |
| MACE | ‚è≥ | ‚è≥ | ‚è≥ | ‚è≥ | ‚è≥ | ‚è≥ | ‚è≥ | ‚è≥ | ‚è≥ | ‚è≥ | Needs setup |
| MolFormer | ‚è≥ | ‚è≥ | ‚è≥ | ‚è≥ | ‚è≥ | ‚è≥ | ‚è≥ | ‚è≥ | ‚è≥ | ‚è≥ | Needs setup |
| Regression Transformer | ‚è≥ | ‚è≥ | ‚è≥ | ‚è≥ | ‚è≥ | ‚è≥ | ‚è≥ | ‚è≥ | ‚è≥ | ‚è≥ | Needs setup |
| ModernBERT | ‚è≥ | ‚è≥ | ‚è≥ | ‚è≥ | ‚è≥ | ‚è≥ | ‚è≥ | ‚è≥ | ‚è≥ | ‚è≥ | Needs setup |
| ChemBERTa | ‚è≥ | ‚è≥ | ‚è≥ | ‚è≥ | ‚è≥ | ‚è≥ | ‚è≥ | ‚è≥ | ‚è≥ | ‚è≥ | Needs setup |
| Equivariant Transformer | ‚è≥ | ‚è≥ | ‚è≥ | ‚è≥ | ‚è≥ | ‚è≥ | ‚è≥ | ‚è≥ | ‚è≥ | ‚è≥ | Needs setup |
| GNN Ablation | ‚è≥ | ‚è≥ | ‚è≥ | ‚è≥ | ‚è≥ | ‚è≥ | ‚è≥ | ‚è≥ | ‚è≥ | ‚è≥ | Needs setup |

## Legend
- ‚úÖ Completed
- üîÑ In Progress  
- ‚è≥ Pending
- ‚ùå Failed
- üö´ Not Applicable

## Next Steps
1. ‚úÖ Complete QM9 dataset processing (in progress)
2. ‚è≥ Run Random Forest baseline on all datasets
3. ‚è≥ Set up and run advanced models
4. ‚è≥ Generate performance comparison plots
5. ‚è≥ Create final results summary

## Notes
- QM9 dataset processing takes ~2 hours due to large size (~134k molecules)
- All datasets auto-generate splits if not present
- Random Forest is the quickest baseline to run
- Advanced models require additional dependencies and setup


Prior research has shown:

Dataset	HoF	Density	HOMO	LUMO	GAP	ZPVE	R¬≤	Œ±	¬µ	C·µ•
Best Performing Model (ID)	MACE	EGNN	ET	ET	ET	Graphormer (3D)	MACE	MACE	ET	MolFormer
Best Performing Model (OOD)	EGNN	TGNN	ET	ET	TGNN	MACE, TGNN	MACE	MACE	MACE	MACE

## HoF Baselines: MACE and EGNN

- MACE HoF
  - Commands:
    ```bash
    cd experiments/mace
    python make_splits.py
    mace_run_train --config=configs/hof.yaml
    python make_plots.py
    ```
  - Outputs:
    - Model: `experiments/mace/hof.model`
    - Plot: `experiments/mace/mace_hof.png`

- EGNN (EquivariantGNN) HoF
  - Runner added: `experiments/gnn-ablation/run_hof_equivariant.py`
  - Command:
    ```bash
    python experiments/gnn-ablation/run_hof_equivariant.py --device cuda --lr 1e-3 --batch_size 32 --epochs 100
    ```
  - Outputs:
    - CSV: `experiments/gnn-ablation/results/results_EquivariantGNN_HoF.csv`
    - Plot: `experiments/gnn-ablation/results/EquivariantGNN_HoF_parity_plot.png`


## NL-MTP HoF Experiment (Neurallambda + Transformer, Policy Evaluation)

### Objective
Train a homoiconic transformer with fast-weights to perform policy evaluation (MTP) on HoF under a fixed policy shift Œ¥=+14 Da (do:W+=Œ¥). Produce ID/OOD RMSE and parity/contrast plots.

### Architecture
- **Model:** 12-layer transformer (40.9M params), emb_dim=512, FFN=2048, heads=8
- **Sequence:** `[ENV] [CONTEXT:x_ctx] [A:mw] <TIME0> [DO:W+=Œ¥] <PROBE>`
- **Time-zero barrier:** Pre-time0 cannot see post-time0 (causal attention mask)
- **LoR fast-weights:** Layers {3,7,11}, rank=8 on Q/K/O attention + MLP-out, gated by Œ±(x,Œ¥)‚àà[0,1]
- **Heads:** Outcome (log HoF), MDN propensity (8 Gaussians), support gate, descriptor-delta

### Data & Features
- **Input:** BOOM HoF dataset with scaffold-based ID/OOD splits
- **Features:** RDKit Morgan FP (2048) + MACCS (167) + 8 descriptors (MolLogP, TPSA, HBA/HBD, etc.)
- **Exposure:** Molecular weight (A = ExactMolWt)
- **Environment:** Hash-based bucketing (16 envs)

### Training
- **Two-pass forward:** Observed-world (no LoR) + Policy-world (LoR active)
- **Losses (fixed weights):**
  - 1.0¬∑L_DR-func (unit-level doubly-robust: y_tilde = m_pol + (y - m_obs)¬∑w)
  - 0.2¬∑L_DR-mean (scalar target: (mean(y_tilde) - œà)¬≤)
  - 1.0¬∑L_obs (supervised MSE on observed world)
  - 0.5¬∑L_mdn (propensity NLL)
  - 0.2¬∑L_rex (per-environment variance)
  - 0.1¬∑L_lor (Œ±¬≤ + Frobenius penalties)
  - 0.2¬∑L_mmp (descriptor delta, epochs 1-5 warmup)
- **Optimizer:** AdamW (lr=2e-4, wd=1e-2), OneCycleLR (2k warmup, cosine), grad clip=1.0
- **Safeguards:** Support gating (s‚â•0.6), importance weight clipping (w‚â§20)

### Implementation
- Location: `experiments/gnn-nlmtp/`
- Files: ‚úÖ `dataset.py`, `model.py`, `trainer.py`, `eval.py`, `run_experiment.py`, `run_experiment.ipynb`
- Status: ‚úÖ **PRODUCTION-READY** (all bugs fixed, see below)

### Commands
```bash
# Script
python experiments/gnn-nlmtp/run_experiment.py --device cuda --batch_size 64 --epochs 30 --delta 14

# Notebook
jupyter notebook experiments/gnn-nlmtp/run_experiment.ipynb
```

### Critical Bugfixes Applied (2025-10-02)

#### üî¥ Bug #1: In-Place Weight Corruption
**Problem:** `_apply_lor()` permanently modified model weights in-place using `.data = ...`, breaking gradients and corrupting weights after first batch.

**Fix:** Rewrote as `_get_adapted_weights()` + `_forward_layer_with_lor()` using functional `F.linear()` with computed adapted weights. Gradients now flow correctly; original weights remain intact.

#### üî¥ Bug #2: Wrong Tensor Shapes  
**Problem:** Dataset returned `torch.tensor([value])` creating shape `[1]` instead of scalars, then used `torch.cat()` instead of `torch.stack()`.

**Fix:** Changed to `torch.tensor(value)` for scalars and `torch.stack()` for proper batching.

#### üî¥ Bug #3: Incorrect LoR Formula
**Problem:** Used `.lerp()` which interpolated between adapted/original weights, canceling adaptation.

**Fix:** Changed to `W_adapted = W_orig + alpha * (U @ V)` for proper low-rank updates.

#### üî¥ Bug #4: Invalid Log Transform for Negative Values (CRITICAL - FIXED ‚úÖ)
**Problem:** HoF values range from -300 to +100 kcal/mol, but code did `log(clamp(y - 1.0, min=1e-6))`. All negative values clamped to `1e-6`, producing same target `log(1e-6) ‚âà -13.8`. Model learned to predict constant ~0.

**Fix Applied (2025-10-02):**
1. Changed `c_offset` from `1.0` to `400.0`
2. Fixed sign error in THREE places:
   - Line 99 `trainer.py`: `log(y - c_offset)` ‚Üí `log(y + c_offset)` ‚úÖ
   - Line 275 `trainer.py`: `exp(m_obs) + c_offset` ‚Üí `exp(m_obs) - c_offset` ‚úÖ
   - Line 280 `trainer.py`: `exp(m_pol) + c_offset` ‚Üí `exp(m_pol) - c_offset` ‚úÖ

**Result:**
- Training: `log(y + 400)` shifts range to `[100, 500]` (valid positive)
- Evaluation: `exp(pred) - 400` converts back to `[-300, +100]`

**‚ö†Ô∏è CRITICAL: Notebook Must Be Restarted!**
- Old buggy code is cached in Jupyter kernel memory
- Must do: Kernel ‚Üí Restart & Run All
- Delete old `results/` folder to avoid confusion

**Expected After Retraining:**
- ‚úÖ Loss decreasing steadily (not flat)
- ‚úÖ ID RMSE < 100 kcal/mol (not 464)
- ‚úÖ OOD RMSE < 150 kcal/mol (not 623)
- ‚úÖ LoR gates active: Œ± ‚âà 0.3-0.7 (not 0.0001)
- ‚úÖ Policy contrast: 5-20 (not 0.0001)

### Model Verification (Architecture Check ‚úÖ)
**Confirmed correct implementation:**
- ‚úÖ OOD data **only** used in evaluation (`_, id_dl, ood_dl = loaders`), never training
- ‚úÖ Training uses only `train_dl` (line 90 trainer.py)
- ‚úÖ Two-pass forward: observed world (`apply_lor=False`) + policy world (`apply_lor=True`)
- ‚úÖ LoR adapts Q/K/O attention + MLP-out at layers {3,7,11}
- ‚úÖ Alpha gate computed from pre-time0 representation
- ‚úÖ Time-zero attention barrier enforced via causal mask
- ‚úÖ All heads present: outcome, MDN propensity, support gate, descriptor-delta
- ‚úÖ DR/AIPW doubly-robust estimation with importance weighting
- ‚úÖ REx environment invariance loss across 16 scaffold buckets
- ‚úÖ Support gating (threshold=0.6) for positivity violation handling

### Explainability Analysis (Updated)
**Note:** Cells 9-17 in notebook use incorrect model attributes and need replacement.
- Use `simplified_explainability.py` instead (works with actual model API)
- Provides: LoR gate stats, support analysis, policy effects, MDN propensity, visualizations
- Cell 18 (summary report) works correctly as-is

### Hyperparameters
- Layers=12, LoR rank=4 on {3,7,11}, K=8 (MDN), Œ¥=+14 Da, batch=64, warmup=5 epochs, c_offset=400


    


+====


